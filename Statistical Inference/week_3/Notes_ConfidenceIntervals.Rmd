T Distribution
Invented by William Gosset with the pseudonym "student" in 1908.
It has a thicker tail than Normal, and is indexed by a degrees of freedom, gets more like a standard normal as df gets larger.

Assume that X is iid drawn from Gaussian with the result that:
(X_hat - mean(X))/(sample_variance / num_sample)^0.5 (X_hat is the sample mean, sample_variance is denoted by S^2)
Interval X_hat + c(-t_(n-1), t_(n-1)) * S / n^0.5, where t_(n-1) is the relevant quantile.
```{r}
data("sleep")
head(sleep)
```

```{r}
g1 = sleep$extra[1:10]
g2 = sleep$extra[11:20]
diff = g2 - g1
diff_mean = mean(diff)
diff_std = sd(diff)
n = 10

diff_mean + c(-1, 1) *qt(0.975, n-1) * diff_std/sqrt(10)
t.test(diff)
t.test(g2, g1, paired = TRUE)
t.test(extra ~ I(relevel(group, 2)), paired = TRUE, data = sleep)
```

Independent Group t Confidence Intervals
The (1 - alpha) * 100% confidence interval for mean(y) - mean(x) is:
Y_hat - X_hat + t_(n_x + n_y - 2, 1 - alpha/2) * S_p(1/(n_x) + 1/(n_y))^(1/2)       (n_x + n_y - 2 is the degrees of freedom)
where S_p is called pooled variance estimator:
S_p^2 = ((n_x - 1)*(S_x)^2 + (n_y - 1)*(S_y)^2) / (n_x + n_y - 2)
This interval is built up an assumption that there's a constant variance across the two groups.
